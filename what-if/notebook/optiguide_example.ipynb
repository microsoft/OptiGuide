{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a461c72d",
   "metadata": {
    "id": "a461c72d"
   },
   "source": [
    "# OptiGuide Example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a05fc7",
   "metadata": {
    "id": "59a05fc7"
   },
   "source": [
    "Here we give a simple example, as designed and illustrated in the [OptiGuide paper](https://arxiv.org/abs/2307.03875).\n",
    "While the original paper is designed specifically for supply chain optimization, the general framework can be easily adapted to other applications with coding capacity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92d200",
   "metadata": {
    "id": "5e92d200"
   },
   "source": [
    "## OptiGuide for Supply Chain Optimization: System Design Overview\n",
    "\n",
    "The original system design for OptiGuide, tailored for supply chain optimization, is presented below.\n",
    "\n",
    "The collaboration among three agents -- Coder, Safeguard, and Interpreter -- lies at the core of this system. They leverage a set of external tools and a large language model (LLM) to address users' questions related to supply chain applications. For a comprehensive understanding of the design and data flow, detailed information can be found in the original [paper](https://arxiv.org/abs/2307.03875).\n",
    "\n",
    "\n",
    "![optiguide system](https://www.beibinli.com/docs/optiguide/optiguide_system.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f90c8",
   "metadata": {
    "id": "8b7f90c8"
   },
   "source": [
    "## New Implementation\n",
    "\n",
    "\n",
    "\n",
    "![](new_design.png)\n",
    "\n",
    "Advantages of this multi-agent design with autogen:\n",
    "- Collaborative Problem Solving: The collaboration among the user proxy agent and the assistant agents fosters a cooperative problem-solving environment. The agents can share information and knowledge, allowing them to complement each other's abilities and collectively arrive at better solutions. On the other hand, the Safeguard acts as a virtual adversarial checker, which can perform another safety check pass on the generated code.\n",
    "\n",
    "- Modularity: The division of tasks into separate agents promotes modularity in the system. Each agent can be developed, tested, and maintained independently, simplifying the overall development process and facilitating code management.\n",
    "\n",
    "- Memory Management: The OptiGuide agent's role in maintaining memory related to user interactions is crucial. The memory retention allows the agents to have context about a user's prior questions, making the decision-making process more informed and context-aware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ReAgLnDma3oI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReAgLnDma3oI",
    "outputId": "c95a23e8-ddb9-4fd2-f218-c40a51cbcbb0"
   },
   "outputs": [],
   "source": [
    "# Install Required Packages\n",
    "# %pip install optiguide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a3b79c4",
   "metadata": {
    "id": "9a3b79c4"
   },
   "outputs": [],
   "source": [
    "# test Gurobi installation\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from eventlet.timeout import Timeout\n",
    "\n",
    "# import auxillary packages\n",
    "import requests  # for loading the example source code\n",
    "import openai\n",
    "\n",
    "# import autogen\n",
    "import autogen\n",
    "from autogen.agentchat import Agent, UserProxyAgent\n",
    "from optiguide import OptiGuideAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf19e7",
   "metadata": {
    "id": "aedf19e7"
   },
   "outputs": [],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4o\",\n",
    "            \"gpt-4\",\n",
    "            \"gpt-4-32k\",\n",
    "            \"gpt-4-32k-0314\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "            \"gpt-3.5-turbo-16k\",\n",
    "            \"gpt-3.5-turbo-0301\",\n",
    "            \"chatgpt-35-turbo-0301\",\n",
    "            \"gpt-35-turbo-v0301\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7e728",
   "metadata": {
    "id": "e9e7e728"
   },
   "source": [
    "Now, let's import the source code (loading from URL) and also some training examples (defined as string blow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca962ac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca962ac5",
    "outputId": "4a789991-8ba1-46f3-aad5-7fbaaaff7f02"
   },
   "outputs": [],
   "source": [
    "# Get the source code of our coffee example\n",
    "code_url = \"https://raw.githubusercontent.com/microsoft/OptiGuide/main/what-if/benchmark/application/coffee.py\"\n",
    "response  = requests.get(code_url)\n",
    "\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the text content from the response\n",
    "    code = response.text\n",
    "else:\n",
    "    raise RuntimeError(\"Failed to retrieve the file.\")\n",
    "# code = open(code_url, \"r\").read() # for local files\n",
    "\n",
    "\n",
    "# show the first head and tail of the source code\n",
    "print(\"\\n\".join(code.split(\"\\n\")[:10]))\n",
    "print(\".\\n\" * 3)\n",
    "print(\"\\n\".join(code.split(\"\\n\")[-10:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31c4b36",
   "metadata": {
    "code_folding": [],
    "id": "e31c4b36"
   },
   "outputs": [],
   "source": [
    "# In-context learning examples.\n",
    "example_qa = \"\"\"\n",
    "----------\n",
    "Question: Why is it not recommended to use just one supplier for roastery 2?\n",
    "Answer Code:\n",
    "```python\n",
    "z = m.addVars(suppliers, vtype=GRB.BINARY, name=\"z\")\n",
    "m.addConstr(sum(z[s] for s in suppliers) <= 1, \"_\")\n",
    "for s in suppliers:\n",
    "    m.addConstr(x[s,'roastery2'] <= capacity_in_supplier[s] * z[s], \"_\")\n",
    "```\n",
    "\n",
    "----------\n",
    "Question: What if there's a 13% jump in the demand for light coffee at cafe1?\n",
    "Answer Code:\n",
    "```python\n",
    "light_coffee_needed_for_cafe[\"cafe1\"] = light_coffee_needed_for_cafe[\"cafe1\"] * (1 + 13/100)\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a7d7e",
   "metadata": {
    "id": "5a5a7d7e"
   },
   "source": [
    "Now, let's create an OptiGuide agent and also a user.\n",
    "\n",
    "For the OptiGuide agent, we only allow \"debug_times\" to be 1, which means it can debug its answer once if it encountered errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53727c",
   "metadata": {
    "id": "af53727c"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "agent = OptiGuideAgent(\n",
    "    name=\"OptiGuideCoffeeExample\",\n",
    "    source_code=code,\n",
    "    debug_times=1,\n",
    "    example_qa=\"\",\n",
    "    llm_config={\n",
    "        \"seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "    }\n",
    ")\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    \"user\", max_consecutive_auto_reply=0,\n",
    "    human_input_mode=\"NEVER\", code_execution_config=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd615e87",
   "metadata": {
    "id": "bd615e87"
   },
   "source": [
    "Now, let's create a user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a76f67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24a76f67",
    "outputId": "2399e32e-fe3f-429f-9c40-fcc75605741d"
   },
   "outputs": [],
   "source": [
    "ans = user.initiate_chat(agent, message=\"What if we prohibit shipping from supplier 1 to roastery 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfac2e1-bc31-45cc-92aa-7983314f9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd1f28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbdd1f28",
    "outputId": "c5e943cf-fce7-4484-8cd8-433d4fede8e5"
   },
   "outputs": [],
   "source": [
    "ans2 = user.initiate_chat(agent, message=\"What is the impact of supplier1 being able to supply only half the quantity at present?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f941680-7111-4212-a0f0-1d70f4931423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ans2.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603fdbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
